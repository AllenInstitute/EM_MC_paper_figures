{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivscc_shiny = pd.read_csv(\"../inh_ivscc_shiny_ttype_and_quality.csv\")\n",
    "ivscc_met_types = pd.read_csv('../20200711_patchseq_metadata_mouse.csv')[['cell_specimen_id','MET-type Label']]\n",
    "\n",
    "ivscc_labels = ivscc_shiny.merge(ivscc_met_types,left_on='spec_id_label',right_on='cell_specimen_id')\n",
    "ivscc_labels = ivscc_labels[ivscc_labels['Tree_call_label']!=\"PoorQ\"]\n",
    "\n",
    "ivscc_features = pd.read_csv(\"../IVSCC_Features_correct_layer_template/RawFeatureWide.csv\")\n",
    "em_features = pd.read_csv(\"./SkKeyFeatures_11_15_2022/RawFeatureWide.csv\")\n",
    "\n",
    "ivscc_merged = ivscc_features.merge(ivscc_labels,left_on='specimen_id',right_on='spec_id_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axon_bias_x',\n",
       " 'axon_bias_y',\n",
       " 'axon_depth_pc_0',\n",
       " 'axon_depth_pc_1',\n",
       " 'axon_depth_pc_2',\n",
       " 'axon_depth_pc_3',\n",
       " 'axon_depth_pc_4',\n",
       " 'axon_emd_with_basal_dendrite',\n",
       " 'axon_exit_distance',\n",
       " 'axon_exit_theta',\n",
       " 'axon_extent_x',\n",
       " 'axon_extent_y',\n",
       " 'axon_frac_above_basal_dendrite',\n",
       " 'axon_frac_below_basal_dendrite',\n",
       " 'axon_frac_intersect_basal_dendrite',\n",
       " 'axon_max_branch_order',\n",
       " 'axon_max_euclidean_distance',\n",
       " 'axon_max_path_distance',\n",
       " 'axon_mean_contraction',\n",
       " 'axon_num_branches',\n",
       " 'axon_soma_percentile_x',\n",
       " 'axon_soma_percentile_y',\n",
       " 'axon_total_length',\n",
       " 'basal_dendrite_bias_x',\n",
       " 'basal_dendrite_bias_y',\n",
       " 'basal_dendrite_calculate_number_of_stems',\n",
       " 'basal_dendrite_extent_x',\n",
       " 'basal_dendrite_extent_y',\n",
       " 'basal_dendrite_frac_above_axon',\n",
       " 'basal_dendrite_frac_below_axon',\n",
       " 'basal_dendrite_frac_intersect_axon',\n",
       " 'basal_dendrite_max_branch_order',\n",
       " 'basal_dendrite_max_euclidean_distance',\n",
       " 'basal_dendrite_max_path_distance',\n",
       " 'basal_dendrite_mean_contraction',\n",
       " 'basal_dendrite_num_branches',\n",
       " 'basal_dendrite_soma_percentile_x',\n",
       " 'basal_dendrite_soma_percentile_y',\n",
       " 'basal_dendrite_stem_exit_down',\n",
       " 'basal_dendrite_stem_exit_side',\n",
       " 'basal_dendrite_stem_exit_up',\n",
       " 'basal_dendrite_total_length',\n",
       " 'soma_aligned_dist_from_pia']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = ivscc_features.columns[1:]\n",
    "catch_flags = [\"area\",\"vol\",\"diam\"]\n",
    "feature_columns = [c for c in feature_columns.tolist() if not any([catch in c for catch in catch_flags])]\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [05:41<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "rfc_met_result_df, rfc_met_results_verbose, all_oob_accuracies = predict_labels_with_probability(source_dataframe=ivscc_merged,\n",
    "                                                                                                prediction_dataframe=em_features,\n",
    "                                                                                                prediction_id_column='specimen_id',\n",
    "                                                                                                feature_columns=feature_columns,\n",
    "                                                                                                label_column='MET-type Label',\n",
    "                                                                                                classifier_method=\"RFC\",\n",
    "                                                                                                min_class_size = 5,\n",
    "                                                                                                min_class_size_subsampling=5,\n",
    "                                                                                                feature_weights=None,\n",
    "                                                                                                num_iterations=500,\n",
    "                                                                                                subsampling_rate=0.95,\n",
    "                                                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5800044052863437, 0.012695007249574107)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_oob_accuracies), np.std(all_oob_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_met_result_df.to_csv(\"EM_MC_Predicted_MET_Labels_11_18_22.csv\")\n",
    "# rfc_met_results_verbose.to_csv(\"EM_MC_Predicted_MET_Labels_11_18_22_verbose_raw_cts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "old_results = pd.read_csv(\"../big_batch_v1/EM_MC_Predicted_MET_Labels_10_3_22.csv\",index_col=0)\n",
    "old_results = old_results.rename(columns={'predicted_MET-type Label':'OLD_pMET','probability':'old_probability'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted_MET-type Label</th>\n",
       "      <th>probability</th>\n",
       "      <th>OLD_pMET</th>\n",
       "      <th>old_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>864691135013417622</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>0.990476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>864691135058985115</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.994</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>864691135118298333</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.598</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.647619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864691135292179382</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>0.846</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>864691135341516741</td>\n",
       "      <td>Sst-MET-9</td>\n",
       "      <td>0.884</td>\n",
       "      <td>Sst-MET-9</td>\n",
       "      <td>0.704762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>864691135374222153</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.996</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.980952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>864691135446065810</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>0.990476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>864691135467660940</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>864691135544588584</td>\n",
       "      <td>Sst-MET-8</td>\n",
       "      <td>0.998</td>\n",
       "      <td>Sst-MET-8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>864691135577202181</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>0.998</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>0.961905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>864691135699487522</td>\n",
       "      <td>Sst-MET-8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Sst-MET-8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>864691135754152141</td>\n",
       "      <td>Sst-MET-5</td>\n",
       "      <td>0.990</td>\n",
       "      <td>Sst-MET-5</td>\n",
       "      <td>0.885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>864691135785592004</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>0.942</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>0.838095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>864691135925834510</td>\n",
       "      <td>Sst-MET-8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Sst-MET-8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>864691135954232584</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.540</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.495238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>864691135988665856</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.986</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>864691136041555030</td>\n",
       "      <td>Sst-MET-5</td>\n",
       "      <td>0.914</td>\n",
       "      <td>Sst-MET-5</td>\n",
       "      <td>0.790476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>864691136116457636</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.996</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>864691136118647832</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Sst-MET-4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>864691136389105936</td>\n",
       "      <td>Sst-MET-5</td>\n",
       "      <td>0.706</td>\n",
       "      <td>Sst-MET-5</td>\n",
       "      <td>0.647619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>864691136618564493</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.984</td>\n",
       "      <td>Sst-MET-6</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>864691136966189518</td>\n",
       "      <td>Sst-MET-5</td>\n",
       "      <td>0.752</td>\n",
       "      <td>Sst-MET-5</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id predicted_MET-type Label  probability   OLD_pMET  \\\n",
       "0   864691135013417622                Sst-MET-4        1.000  Sst-MET-4   \n",
       "1   864691135058985115                Sst-MET-6        0.994  Sst-MET-6   \n",
       "2   864691135118298333                Sst-MET-6        0.598  Sst-MET-6   \n",
       "3   864691135292179382                Sst-MET-4        0.846  Sst-MET-4   \n",
       "5   864691135341516741                Sst-MET-9        0.884  Sst-MET-9   \n",
       "6   864691135374222153                Sst-MET-6        0.996  Sst-MET-6   \n",
       "7   864691135446065810                Sst-MET-4        1.000  Sst-MET-4   \n",
       "8   864691135467660940                Sst-MET-4        1.000  Sst-MET-4   \n",
       "9   864691135544588584                Sst-MET-8        0.998  Sst-MET-8   \n",
       "10  864691135577202181                Sst-MET-4        0.998  Sst-MET-4   \n",
       "11  864691135699487522                Sst-MET-8        1.000  Sst-MET-8   \n",
       "12  864691135754152141                Sst-MET-5        0.990  Sst-MET-5   \n",
       "13  864691135785592004                Sst-MET-4        0.942  Sst-MET-4   \n",
       "14  864691135925834510                Sst-MET-8        1.000  Sst-MET-8   \n",
       "15  864691135954232584                Sst-MET-6        0.540  Sst-MET-6   \n",
       "16  864691135988665856                Sst-MET-6        0.986  Sst-MET-6   \n",
       "17  864691136041555030                Sst-MET-5        0.914  Sst-MET-5   \n",
       "18  864691136116457636                Sst-MET-6        0.996  Sst-MET-6   \n",
       "19  864691136118647832                Sst-MET-4        1.000  Sst-MET-4   \n",
       "20  864691136389105936                Sst-MET-5        0.706  Sst-MET-5   \n",
       "21  864691136618564493                Sst-MET-6        0.984  Sst-MET-6   \n",
       "22  864691136966189518                Sst-MET-5        0.752  Sst-MET-5   \n",
       "\n",
       "    old_probability  \n",
       "0          0.990476  \n",
       "1          0.971429  \n",
       "2          0.647619  \n",
       "3          0.714286  \n",
       "5          0.704762  \n",
       "6          0.980952  \n",
       "7          0.990476  \n",
       "8          1.000000  \n",
       "9          1.000000  \n",
       "10         0.961905  \n",
       "11         1.000000  \n",
       "12         0.885714  \n",
       "13         0.838095  \n",
       "14         1.000000  \n",
       "15         0.495238  \n",
       "16         0.952381  \n",
       "17         0.790476  \n",
       "18         1.000000  \n",
       "19         1.000000  \n",
       "20         0.647619  \n",
       "21         0.857143  \n",
       "22         0.619048  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = rfc_met_result_df.merge(old_results,on='id')\n",
    "merged[merged['predicted_MET-type Label']==merged['OLD_pMET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels_with_probability(source_dataframe,\n",
    "                                    prediction_dataframe,\n",
    "                                    prediction_id_column,\n",
    "                                    feature_columns,\n",
    "                                    label_column,\n",
    "                                    classifier_method,\n",
    "                                    min_class_size = 5,\n",
    "                                    min_class_size_subsampling=5,\n",
    "                                    feature_weights=None,\n",
    "                                    num_iterations=500,\n",
    "                                    subsampling_rate=0.95,\n",
    "                                   ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given morpho feature data collected from patch-seq (IVSCC) and EM, we will predict the MET cell type labels\n",
    "    from patch-seq to the EM cells. \n",
    "\n",
    "\n",
    "    :param source_dataframe: dataframe, the training dataframe (IVSCC) must have all feature_columns and label_column (e.g. met_type)\n",
    "    :param prediction_dataframe: dataframe, the dataframe you would like to assign labels to, must have all feature columns and an id column\n",
    "    :param prediction_id_column: str, specimen id column in the prediction dataframe\n",
    "    :param feature_columns: list of features, must be present in both dataframes\n",
    "    :param label_column: str, what column from the source_dataframe  you want to predict \n",
    "    :param classifier_method: str, [KNN or RFC]\n",
    "    :param min_class_size: int, the smallest representation allowed in training data, instances from a class with fewer than this value will be dropped\n",
    "    :param min_class_size_subsampling: int, when subsampling, what is the smallest you want to erode any given class of training data\n",
    "    :param feature_weights: list/array of feature weights if you want to scale them for any distance based metrics\n",
    "    :param num_iterations: int, how many iterations of classification to run\n",
    "    :param subsampling_rate: float in range 0-1.0. Represents the percent of IVSCC cells to subsample in each iteration\n",
    "\n",
    "\n",
    "    :return: result_df: dataframe, has the following columns: [\"id\",'predicted_label_column','probability']\n",
    "    :return: results: mxn numpy array, m = prediction cells, n=all unique possible labels, the ith,jth value indicates how \n",
    "    many times the ith cell was predited to be the jth label\n",
    "    :return: all_accuracies: list, keeps track of either oob_score or training error of each classifier\n",
    "    \"\"\"\n",
    "\n",
    "    prediction_dataframe.fillna(0,inplace=True)\n",
    "    \n",
    "    source_dataframe=source_dataframe.copy()\n",
    "    \n",
    "    labels_above_threshold = [k for k,v in source_dataframe[label_column].value_counts().to_dict().items() if v>=min_class_size]\n",
    "    source_dataframe = source_dataframe[source_dataframe[label_column].isin(labels_above_threshold)]\n",
    "    \n",
    "    num_source_datapoints_to_drop = int(len(source_dataframe)*(1-subsampling_rate))\n",
    "\n",
    "    if not feature_weights:\n",
    "        feature_weights = [1]*len(feature_columns)\n",
    "        \n",
    "    prediction_data_array = prediction_dataframe[feature_columns].values\n",
    "    prediction_data_array = np.multiply(prediction_data_array,feature_weights)\n",
    "    prediction_ids = prediction_dataframe[prediction_id_column].tolist()\n",
    "    \n",
    "    unique_labels = source_dataframe[label_column].unique().tolist()\n",
    "    results = np.zeros((len(prediction_ids), len(unique_labels)))\n",
    "    \n",
    "\n",
    "    all_accuracies = []\n",
    "    for outter_it in tqdm(range(num_iterations)):\n",
    "        #subsample the entirety of our source dataset according to subsampling_rate\n",
    "        source_labels_value_counts = source_dataframe[label_column].value_counts().to_dict()\n",
    "        source_dataframe_subsampled = source_dataframe.copy(deep=True)\n",
    "        for _ in range(num_source_datapoints_to_drop):\n",
    "\n",
    "            available_labels_to_drop = [k for k,v in source_labels_value_counts.items() if v>min_class_size_subsampling]\n",
    "            current_number_of_cells = sum([source_labels_value_counts[v] for v in available_labels_to_drop])\n",
    "            probability_of_available_labels = [source_labels_value_counts[k]/current_number_of_cells for k in available_labels_to_drop]\n",
    "            if available_labels_to_drop:\n",
    "                label_to_drop = np.random.choice(available_labels_to_drop,p=probability_of_available_labels)\n",
    "                idx_to_drop = np.random.choice(source_dataframe_subsampled[source_dataframe_subsampled[label_column]==label_to_drop].index)\n",
    "                source_dataframe_subsampled = source_dataframe_subsampled.drop(idx_to_drop)\n",
    "                source_labels_value_counts[label_to_drop] = source_labels_value_counts[label_to_drop] - 1 \n",
    "\n",
    "                \n",
    "\n",
    "        \n",
    "        feature_values = source_dataframe_subsampled[feature_columns].values\n",
    "        feature_values = np.multiply(feature_values,feature_weights)\n",
    "        labels = source_dataframe_subsampled[label_column].values\n",
    "        \n",
    "        \n",
    "        if classifier_method == \"RFC\":\n",
    "            classifier = RandomForestClassifier(n_estimators=200,\n",
    "                                                 random_state=0,\n",
    "                                                 min_samples_leaf=3,\n",
    "                                                 min_samples_split=3,\n",
    "                                                 oob_score=True,\n",
    "                                                 max_depth = None, \n",
    "                                                 class_weight='balanced'\n",
    "                                                )\n",
    "            \n",
    "        elif classifier_method == \"KNN\":\n",
    "            classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "            \n",
    "        else:\n",
    "            print(\"Invalid classifier_method passed\")\n",
    "            return None,None,None\n",
    "        \n",
    "        classifier.fit(feature_values, labels)\n",
    "        \n",
    "        if hasattr(classifier, 'oob_score'):\n",
    "            all_accuracies.append(classifier.oob_score_)\n",
    "            \n",
    "        else:\n",
    "            all_accuracies.append(classifier.score(feature_values, labels))\n",
    "\n",
    "        predictions = classifier.predict(prediction_data_array)\n",
    "        predictions_by_id = dict(zip(prediction_ids,predictions))\n",
    "        # keep track of predictions \n",
    "        for sample_id, pred_label in predictions_by_id.items():\n",
    "            row_idx = prediction_ids.index(sample_id)\n",
    "            col_ids = unique_labels.index(pred_label)\n",
    "            results[row_idx, col_ids]+=1\n",
    "        \n",
    "       \n",
    "    # create simple dataframe     \n",
    "    chosen_label_indices = np.argmax(results,axis=1)\n",
    "    chosen_label_occurence = np.max(results,axis=1)\n",
    "    chosen_labels = [unique_labels[i] for i in chosen_label_indices]\n",
    "    probability = chosen_label_occurence/num_iterations\n",
    "\n",
    "    result_df = pd.DataFrame({\"id\":prediction_ids,\n",
    "                 f\"predicted_{label_column}\":chosen_labels,\n",
    "                 \"probability\":probability})\n",
    "\n",
    "    return result_df, results, all_accuracies\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:new_neuron_morph_no_bug] *",
   "language": "python",
   "name": "conda-env-new_neuron_morph_no_bug-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
